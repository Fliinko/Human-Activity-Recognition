{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"DataSet/train.csv\")\n",
    "test = pd.read_csv(\"DataSet/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train.columns\n",
    "\n",
    "# Removing '()' from column names\n",
    "columns = columns.str.replace('[()]','')\n",
    "columns = columns.str.replace('[-]','')\n",
    "columns = columns.str.replace('[,]','')\n",
    "\n",
    "train.columns = columns\n",
    "test.columns =columns\n",
    "\n",
    "train_float = train.copy()\n",
    "\n",
    "train_float.loc[(train_float['Activity'] == 'STANDING')] = 0\n",
    "train_float.loc[(train_float['Activity'] == 'SITTING')] = 1\n",
    "train_float.loc[(train_float['Activity'] == 'LAYING')] = 2\n",
    "train_float.loc[(train_float['Activity'] == 'WALKING')] = 3\n",
    "train_float.loc[(train_float['Activity'] == 'WALKING_DOWNSTAIRS')] = 4\n",
    "train_float.loc[(train_float['Activity'] == 'WALKING_UPSTAIRS')] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.Activity\n",
    "y_train_float = train_float.Activity\n",
    "X_train = train.drop(['subject', 'Activity'], axis=1)\n",
    "y_test = test.Activity\n",
    "X_test = test.drop(['subject', 'Activity'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', 'WALKING_UPSTAIRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic function to run any model specified\n",
    "def perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, print_cm=True, cm_map=plt.cm.Greens):\n",
    "    # to store results at various phases\n",
    "    results = dict()\n",
    "    \n",
    "    # time at which model starts training\n",
    "    train_start_time = datetime.now()\n",
    "    print('training the model..')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Done\\n\\n\")\n",
    "    train_end_time = datetime.now()\n",
    "    results['training_time'] = train_end_time - train_start_time\n",
    "    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n",
    "    \n",
    "    # predict test data\n",
    "    print('Predicting test data')\n",
    "    test_start_time = datetime.now()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_end_time = datetime.now()\n",
    "    print('Done\\n\\n')\n",
    "    results['testing_time'] = test_end_time - test_start_time\n",
    "    print('testing_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['testing_time']))\n",
    "    results['predicted'] = y_pred\n",
    "    \n",
    "    # calculate overall accuracty of the model\n",
    "    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    # store accuracy in results\n",
    "    results['accuracy'] = accuracy\n",
    "    print('-----------------------')\n",
    "    print('|       Accuracy      |')\n",
    "    print('-----------------------')\n",
    "    print('\\n      {}\\n\\n'.format(accuracy))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    results['confusion_matrix'] = cm\n",
    "    if print_cm:\n",
    "        print('-----------------------')\n",
    "        print('|   Confusion Matrix  |')\n",
    "        print('-----------------------')\n",
    "        print('\\n {}'.format(cm))\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.grid(b=False)\n",
    "    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized Confusion Matrix', cmap=cm_map)\n",
    "    plt.show()\n",
    "    \n",
    "    # get classification report\n",
    "    print('-----------------------------')\n",
    "    print('|   Classification Report   |')\n",
    "    print('-----------------------------')\n",
    "    classification_report = metrics.classification_report(y_test, y_pred)\n",
    "    \n",
    "    # store report in results\n",
    "    results['classification_report'] = classification_report\n",
    "    print(classification_report)\n",
    "    \n",
    "    # add the trained model to the results\n",
    "    results['model'] = model\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print the gridsearch Attributes\n",
    "def print_grid_search_attributes(model):\n",
    "    # Estimator that gave highest score among all the estimators formed in GridSearch\n",
    "    print('-----------------------')\n",
    "    print('|    Best Estimator   |')\n",
    "    print('-----------------------')\n",
    "    print('\\n\\t{}\\n'.format(model.best_estimator_))\n",
    "    \n",
    "    # parameters that gave best results while performing grid search\n",
    "    print('-----------------------')\n",
    "    print('|   Best Parameters   |')\n",
    "    print('-----------------------')\n",
    "    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n",
    "    \n",
    "    # number of cross validation splits\n",
    "    print('--------------------------------')\n",
    "    print('|  No of CrossValidation sets  |')\n",
    "    print('--------------------------------')\n",
    "    print('\\n\\tTotal number of cross validation sets: {}\\n'.format(model.n_splits_))\n",
    "    \n",
    "    # Average cross validated score of the best estimator, from the Grid Search\n",
    "    print('-----------------------')\n",
    "    print('|      Best Score     |')\n",
    "    print('-----------------------')\n",
    "    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_params = {'n_neighbors':[2, 3, 4, 5, 6, 7]} # k = 7 (90.2%)\n",
    "knn_params = {'n_neighbors':[11, 13, 15, 17, 19], 'weights': ['uniform','distance'], 'algorithm': ['ball_tree', 'kd_tree','brute']}\n",
    "knn_kernel = neighbors.KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn_kernel, param_grid=knn_params, n_jobs=-1, verbose=1)\n",
    "knn_grid_results = perform_model(knn_grid, X_train, y_train, X_test, y_test,class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_search_attributes(knn_grid_results['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel_knn = neighbors.KNeighborsClassifier(n_neighbors=17, weights=\"distance\", algorithm=\"ball_tree\")\n",
    "best_svm_results = perform_model(best_kernel_knn, X_train, y_train, X_test, y_test,class_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_params = {'C':[0.125, 0.5, 1, 2, 8, 16]} # best param 0.5 (0.962)\n",
    "lr_params = {'C':[0.25, 0.3, 0.5, 0.7, 0.8]} # best param 0.5 (0.963)\n",
    "lr_kernel = svm.SVC(kernel='linear')\n",
    "lr_svc_grid = GridSearchCV(lr_kernel, param_grid=lr_params, n_jobs=-1, verbose=1)\n",
    "lr_svc_grid_results = perform_model(lr_svc_grid, X_train, y_train, X_test, y_test,class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_search_attributes(lr_svc_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial Basis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_kernel = svm.SVC(kernel='rbf')\n",
    "rbf_params = {'C':[55, 60, 65, 81, 90], 'gamma':['scale', 0.01, 0.03, 0.05, 0.07]}\n",
    "rbf_svc_grid = GridSearchCV(rbf_kernel, param_grid=rbf_params, n_jobs=-1, verbose=1)\n",
    "rbf_svc_grid_results = perform_model(rbf_svc_grid, X_train, y_train, X_test, y_test,class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_search_attributes(rbf_svc_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_kernel = svm.SVC(kernel='sigmoid')\n",
    "sig_params = {'C':[0.125, 0.5, 1, 2, 8, 16]}\n",
    "sig_svc_grid = GridSearchCV(sig_kernel, param_grid=sig_params, n_jobs=-1, verbose=1)\n",
    "sig_svc_grid_results = perform_model(sig_svc_grid, X_train, y_train, X_test, y_test,class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_search_attributes(lr_svc_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_kernel = svm.SVC(kernel='poly')\n",
    "# poly_params = {'C':[0.125, 0.5, 1, 2, 8, 16], 'degree': [1, 2, 3, 4, 5]} # best params: C: 2, degree: 4\n",
    "poly_params = {'C':[3, 2, 4, 5], 'degree': [3, 4, 5]}\n",
    "poly_svc_grid = GridSearchCV(poly_kernel, param_grid=poly_params, n_jobs=-1, verbose=1)\n",
    "poly_svc_grid_results = perform_model(poly_svc_grid, X_train, y_train, X_test, y_test,class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_search_attributes(poly_svc_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel_svm = svm.SVC(kernel='rbf', C=60, gamma=0.01)\n",
    "best_svm_results = perform_model(best_kernel_svm, X_train, y_train, X_test, y_test,class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA() # By default, PCA() centers the data, but does not scale it.\n",
    "# X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# per_var = np.round(pca.explained_variance_ratio_*100, decimals=1)\n",
    "# labels = [str(x) for x in range(1, len(per_var)+1)]\n",
    "\n",
    "# plt.bar(x=range(1, len(per_var)+1), height=per_var)\n",
    "# plt.tick_params(\n",
    "#     axis='x',\n",
    "#     which='both',\n",
    "#     bottom=False,\n",
    "#     top=False,\n",
    "#     labelbottom=False)\n",
    "# plt.ylabel('Percentage of Explained Variance')\n",
    "# plt.xlabel('Principal Components')\n",
    "# plt.ylim([0,10])\n",
    "# plt.title('Scree Plot')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pc1_coords = X_train_pca[:, 0]\n",
    "# train_pc2_coords = X_train_pca[:, 1]\n",
    "\n",
    "# pca_train = np.column_stack((train_pc1_coords,train_pc2_coords))\n",
    "\n",
    "# param_grid = [\n",
    "#     {'C': [1, 10, 100, 1000],\n",
    "#      'gamma': ['scale', 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#      'kernel': ['rbf']},\n",
    "# ]\n",
    "\n",
    "# optimal_params = GridSearchCV(\n",
    "#         svm.SVC(),\n",
    "#         param_grid,\n",
    "#         cv=5,\n",
    "#         scoring='accuracy',\n",
    "#         n_jobs=-1,\n",
    "#         verbose=1)\n",
    "\n",
    "# optimal_params.fit(pca_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_params = {'C':[0.001, 0.125, 0.5, 1, 8, 16, 50], 'class_weight':['balanced',None], \n",
    "#               'solver':[ 'newton-cg', 'sag', 'saga', 'lbfgs'], 'multi_class':['ovr', 'multinomial']} acc : 96.26%\n",
    "# reg_params = {'C':[ 9, 10, 11, 14], 'class_weight':['balanced'], \n",
    "#               'solver':[ 'lbfgs'], 'multi_class':['ovr', ' multinomial']} acc : 96.3%\n",
    "reg_params = {'C':[ 9, 10, 11, 14], 'class_weight':['balanced'], 'solver':[ 'lbfgs'], 'multi_class':['ovr'],\n",
    "              'penalty': ['l1','l2','elasticnet','none']}\n",
    "reg_kernel = linear_model.LogisticRegression()\n",
    "reg_grid = GridSearchCV(reg_kernel, param_grid=reg_params, n_jobs=-1, verbose=1)\n",
    "reg_grid_results = perform_model(reg_grid, X_train, y_train, X_test, y_test,class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_search_attributes(reg_grid_results['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_kernel_reg = linear_model.LogisticRegression(C=10, penalty='l2', class_weight='balanced', solver='lbfgs', multi_class='ovr', max_iter=200)\n",
    "best_reg_results = perform_model(best_kernel_reg, X_train, y_train, X_test, y_test,class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
